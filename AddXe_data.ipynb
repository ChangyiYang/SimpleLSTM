{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is aimed to add Xe to the model and see if the model can be improved\n",
    "from src.DataPrepocessing import *\n",
    "from src.NeuralNets import *\n",
    "from src.TrainMethod import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Propocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will generate a file with following parts\n",
    "* Keff\n",
    "* Power\n",
    "* Threshold\n",
    "* Histogramed Cs\n",
    "* Histogramed Xe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, get the keff power and threshold from tracked_results.csv\n",
    "\n",
    "core_file = pd.read_csv(\"./Raw Data/Add Xe/tracked_results.csv\")\n",
    "core_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_columns = [\"keff\", \"power_normalization_value\", \"threshold\"]\n",
    "core_data = core_file[extract_columns].to_numpy()\n",
    "core_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the histogramed version of Cs and Xe\n",
    "\n",
    "def generate_histogram(data: np.ndarray, binInt = 1.0e-06, binMax = 1.5e-04):\n",
    "    '''\n",
    "    Take in a data with columns are features  Transform the features with histogram method\n",
    "    '''\n",
    "\n",
    "    # Extract data\n",
    "    Xvals = data\n",
    "\n",
    "    nRows, nCols = Xvals.shape\n",
    "\n",
    "    # define bins\n",
    "    hEdges = np.arange(0, binMax+binInt, binInt)\n",
    "    nBins = len(hEdges)-1\n",
    "\n",
    "\n",
    "    # fill histogram matrix\n",
    "    nCountsX = np.zeros((nRows, nBins), dtype=np.uint16)\n",
    "    for n in range(nRows):\n",
    "        nCountsX[n,:], _ = np.histogram(Xvals[n,:], hEdges)\n",
    "    return nCountsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 150)\n",
      "(1309, 150)\n"
     ]
    }
   ],
   "source": [
    "Cs137_file = pd.read_csv(\"./Raw Data/Add Xe/Cs137.csv\").to_numpy()\n",
    "Xe135_file = pd.read_csv(\"./Raw Data/Add Xe/Xe135.csv\").to_numpy()\n",
    "\n",
    "\n",
    "histogramed_Cs137 = generate_histogram(Cs137_file)\n",
    "histogramed_Xe135 = generate_histogram(Xe135_file)\n",
    "\n",
    "\n",
    "print(histogramed_Cs137.shape)\n",
    "print(histogramed_Xe135.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1308, 3)\n",
      "(1308, 150)\n",
      "(1308, 150)\n"
     ]
    }
   ],
   "source": [
    "# do the time align\n",
    "# although it does not have a clear effect on the result\n",
    "\n",
    "core_data = core_data[1:]\n",
    "\n",
    "histogramed_Cs137 = histogramed_Cs137[:-1]\n",
    "histogramed_Xe135 = histogramed_Xe135[:-1]\n",
    "\n",
    "print(core_data.shape)\n",
    "print(histogramed_Cs137.shape)\n",
    "print(histogramed_Xe135.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 303)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = np.concatenate((core_data, histogramed_Cs137, histogramed_Xe135), axis=1)\n",
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97026873, 0.9686063 , 0.96600921, ..., 0.95942264, 0.95950929,\n",
       "       0.95917451])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the first column is the keff\n",
    "\n",
    "total_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the data \n",
    "\n",
    "# Save the array as a CSV file\n",
    "np.savetxt('./Processed Data/Cs_Xe.csv', total_data, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
