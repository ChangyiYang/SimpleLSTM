{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b32cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this file requires reinserted_fuel_{i}.csv files numbered 0 through 195 to be downloaded locally\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a07570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block produces a csv file of k_eff data and fluence data by timestep, which is not actually relevant to our work\n",
    "# \n",
    "\n",
    "k_eff_table = pd.read_csv(\"./data/tracked_Cs137_195.csv\")\n",
    "k_eff = k_eff_table[\"keff [/]\"].values\n",
    "k_eff_unc = k_eff_table[\"keff_relative_uncertainty [/]\"].values\n",
    "csv_data = []\n",
    "\n",
    "for i in range(0, 196):\n",
    "    file_name = f\"reinserted_fuel_{i}.csv\"\n",
    "    fluence_row = read_thermal_fluence(file_name)\n",
    "    fluence_row = np.insert(fluence_row, 0, i)\n",
    "    fluence_row = np.insert(fluence_row, 1, k_eff[i])\n",
    "    fluence_row = np.insert(fluence_row, 2, k_eff_unc[i])\n",
    "    csv_data.append(fluence_row)\n",
    "\n",
    "max_len = len(max(csv_data, key=len))\n",
    "for i in range(0, 196):\n",
    "    csv_data[i] = np.pad(csv_data[i], (0, max_len-csv_data[i].size), 'constant', constant_values=(0))\n",
    "\n",
    "#np.savetxt(\"reinserted_thermal_fluence.csv\", csv_data, delimiter=\",\", header='timestamp, keff, keff_unc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45aee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a comma separated string representation of the column headers for the fluence table. \n",
    "\n",
    "cesium_list = [\"cesium_val\"] * 812\n",
    "for i in range(len(cesium_list)):\n",
    "    cesium_list[i] = cesium_list[i] + \"_\" + str(i)\n",
    "cesium_list.append(\"final_cesium_val\")\n",
    "fluence_list = [\"fluence_val\"] * 813\n",
    "for i in range(len(fluence_list)):\n",
    "    fluence_list[i] = fluence_list[i] + \"_\" + str(i)\n",
    "header = cesium_list + fluence_list\n",
    "header_str = ','.join(header)\n",
    "header_str = \"timestamp,\" + header_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7051250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates fluence table, including cesium values and fluence values at each timestep as rows. \n",
    "\n",
    "cesium_table = pd.read_csv(\"./data/tracked_Cs137_195.csv\")\n",
    "csv_data = []\n",
    "\n",
    "for i in range(0, 196):\n",
    "    cesium_row = cesium_table.iloc[i].values[3:]\n",
    "    file_name = f\"reinserted_fuel_{i}.csv\"\n",
    "    fluence_row = read_thermal_fluence(file_name)\n",
    "    fluence_row = np.append(cesium_row, fluence_row)\n",
    "    fluence_row = np.insert(fluence_row, 0, i)\n",
    "    csv_data.append(fluence_row)\n",
    "\n",
    "max_len = len(max(csv_data, key=len))\n",
    "for i in range(0, 196):\n",
    "    csv_data[i] = np.pad(csv_data[i], (0, max_len-csv_data[i].size), 'constant', constant_values=(0))\n",
    "\n",
    "np.savetxt(\"reinserted_thermal_fluence.csv\", csv_data, delimiter=\",\", header=header_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a5bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_thermal_fluence(file_name):\n",
    "    data = pd.read_csv(\"./data/reinserted_data/\" + file_name)\n",
    "    fluence = data[\"integrated_flux_pebbles_thermal\"].values\n",
    "    return fluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0ea7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.14281000e+00, 5.00000000e-04, 1.25737990e+21, ...,\n",
       "        5.28426720e+19, 5.93523420e+20, 6.44841369e+21])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluence_195 = read_thermal_fluence(\"reinserted_fuel_195.csv\")\n",
    "fluence_195 = np.insert(fluence_195, 0, k_eff[0])\n",
    "fluence_195 = np.insert(fluence_195, 1, k_eff_unc[0])\n",
    "fluence_195\n",
    "megaarr = []\n",
    "megaarr.append(fluence_195)\n",
    "megaarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06e937af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 0]), array([4, 5, 6, 8]), array([4, 0, 0, 0])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = [[1, 2, 3], [4, 5, 6, 8], [4, 0]]\n",
    "max_len = len(max(test_arr, key=len))\n",
    "for i in range(len(test_arr)):\n",
    "    test_arr[i] = np.pad(test_arr[i], (0, max_len-len(test_arr[i])), 'constant', constant_values=(0))\n",
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e952596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fluence_195 = read_thermal_fluence(\"data_195.csv\")\n",
    "#csv_data.loc[0] = fluence_195\n",
    "#csv_data.loc[0] = [1, 2]\n",
    "#example_data \n",
    "#example_data.append(fluence_195)\n",
    "#example_data.append(fluence_195)\n",
    "#np.savetxt(\"test_file.csv\", [fluence_195, fluence_195], delimiter=\",\")\n",
    "#np.savetxt(\"test_file.csv\", [fluence_195], delimiter=\",\")\n",
    "#example_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97c0d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_eff_table = pd.read_csv(\"./data/tracked_Cs137_195.csv\")\n",
    "fluence_195 = read_thermal_fluence(\"reinserted_fuel_195.csv\")\n",
    "cesium_195 = k_eff_table.iloc[3].values[3:]\n",
    "#fluence_195 = np.transpose(fluence_195) + np.transpose(cesium_195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aaa1554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cesium_195 = cesium_195.reshape((813, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb8406aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fluence_195 = fluence_195.reshape((787, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72c7e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.append(cesium_195, fluence_195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdead3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.24693827e-06, 2.87269835e-06, 2.73721273e-06, ...,\n",
       "       1.17185341e+21, 7.56970874e+20, 1.10664572e+21])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920f119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
